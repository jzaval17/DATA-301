{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUYibBNeVkzu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYn8_-z8VpNt"
      },
      "source": [
        "##Assignment – Build a classifier for detecting Mines and Determine Influence of k in K‑Nearest Neighbours on the UCI Sonar Dataset\n",
        "\n",
        " There are two classes - mine \"M\" (positive class, label 1) and rock \"R\" (negative class, label 0)\n",
        "\n",
        "**Learning goals**\n",
        "\n",
        "-- Detect and reason about class imbalance.\n",
        "\n",
        "-- Evaluate two -values (3 and 5) for K‑NN using proper cross‑validation.\n",
        "\n",
        "-- Compare accuracy to class‑sensitive metrics (precision, recall, F1).\n",
        "\n",
        "-- Practise writing result tables and interpreting trade‑offs.\n",
        "\n",
        "-- (Extension) Experiment with a third classifier of your choice.\n",
        "\n",
        "**Load dataset**\n",
        "use the following command to convert the string labels into categorical\n",
        "```\n",
        "y = df['Label'].astype('category').cat.codes\n",
        "```\n",
        "**Part 1  Exploratory Check**\n",
        "\n",
        "- Missing values  Report the count of NaN values in the raw CSV.\n",
        "\n",
        "- Class balance: (a) Display a bar plot of R vs M counts.\n",
        "\n",
        "(b) Compute the imbalance ratio (larger‑class ∕ smaller‑class).\n",
        "\n",
        "(c) Decide whether the dataset is balanced or imbalanced (justify). This is upto your discretion.\n",
        "\n",
        "\n",
        "\n",
        "**Part 2  Modelling**\n",
        "\n",
        "- Perform 80 / 20 train‑test split (stratified if imbalanced).\n",
        "\n",
        "- use StandardScaler → KNeighborsClassifier inside each fold.\n",
        "\n",
        "- 5‑fold CV (use StratifiedKFold when imbalanced, plain KFold otherwise).\n",
        "\n",
        "- Evaluate two models: Model  (a) KNN n_neighbors = 3 (b) KNN n_neighbors = 5\n",
        "\n",
        "- For each model record:\n",
        "\n",
        "i) Mean training accuracy (across folds)\n",
        "\n",
        "ii) Mean validation accuracy\n",
        "\n",
        "iii) Gap = train − val\n",
        "\n",
        "- Test accuracy on the held‑out 20 % split\n",
        "\n",
        "- Confusion matrix on the test set\n",
        "\n",
        "- Precision, recall, F1  \n",
        "\n",
        "Fill the required metrics into the table template below (extend it with the new columns for precision/recall/F1):\n",
        "\n",
        "| k | Train Acc | Val Acc | Gap | Test Acc | Precision | Recall | F1 | Confusion Matrix | Best |\n",
        "| :-: | :-------: | :-----: | :--: | :------: | :-------: | :----: | :---: | :--------------- | :--: |\n",
        "\n",
        "Q1: State the best model whichever model you would deploy if the main goal is to minimise missed mines (maximise recall).\n",
        "\n",
        "Make your judgement using the following reasong - If Based on your validation accuracy for k = 3 looked best, but the hold-out test shows k = 5 has higher balanced accuracy. Which would you deploy given that missing a mine carries greater risk than a false alarm?”\n",
        "\n",
        "I would end up deploying k=3 because it recieved a Recall = 0.6500, where k=5 catches a Recall = 0.6000. k=5 did have a slightly higher Test Accuracy  (0.7381 vs. 0.7143), k=3 catches a larger fraction of actual mines (13/20 vs. 12/20). In mine-hunting a false negative would be far more dangerous than a false positive. So we pick the model with higher recall for class \"M\" even if overall accuracy is a little lower.\n",
        "\n",
        "**Part 3  Interpretation Questions**\n",
        "\n",
        "Q2: Class imbalance – How severe is it, and which metric (precision vs recall) carries more significance in a sonar mine‑hunting scenario?\n",
        "\n",
        "Q3: k = 3 vs k=5 – Compare validation vs test results. Which k generalises better?\n",
        "\n",
        "Q4:   Error profile – Using the confusion matrices, state whether false positives or false negatives dominate and discuss practical impact.\n",
        "\n",
        "**Part 4  Extension (Open‑Ended)**\n",
        "\n",
        "- Pick one additional classifier such as SVC:\n",
        "\n",
        "- Evaluate it with the same pipeline and metrics (include precision/recall/F1).\n",
        "\n",
        "- Add a new row to the results table.\n",
        "\n",
        "- State whether it improves over KNN and why that might be.\n",
        "\n",
        "\n",
        "Note: Precision, recall, F1 scores can be returned for both the classes. For the assignment we stick to the single-scalar version focused on mines. For precision, recall calculate with respect to the positive class denoted by class label 1. Note the variables denoting the test splits can change based on what you have used.\n",
        "\n",
        "```\n",
        "prec = precision_score(y_te, y_pred, pos_label=1)\n",
        "rec  = recall_score(y_te, y_pred, pos_label=1)\n",
        "f1   = f1_score(y_te, y_pred, pos_label=1)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature_0</th>\n",
              "      <th>Feature_1</th>\n",
              "      <th>Feature_2</th>\n",
              "      <th>Feature_3</th>\n",
              "      <th>Feature_4</th>\n",
              "      <th>Feature_5</th>\n",
              "      <th>Feature_6</th>\n",
              "      <th>Feature_7</th>\n",
              "      <th>Feature_8</th>\n",
              "      <th>Feature_9</th>\n",
              "      <th>...</th>\n",
              "      <th>Feature_51</th>\n",
              "      <th>Feature_52</th>\n",
              "      <th>Feature_53</th>\n",
              "      <th>Feature_54</th>\n",
              "      <th>Feature_55</th>\n",
              "      <th>Feature_56</th>\n",
              "      <th>Feature_57</th>\n",
              "      <th>Feature_58</th>\n",
              "      <th>Feature_59</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Freq_1</td>\n",
              "      <td>Freq_2</td>\n",
              "      <td>Freq_3</td>\n",
              "      <td>Freq_4</td>\n",
              "      <td>Freq_5</td>\n",
              "      <td>Freq_6</td>\n",
              "      <td>Freq_7</td>\n",
              "      <td>Freq_8</td>\n",
              "      <td>Freq_9</td>\n",
              "      <td>Freq_10</td>\n",
              "      <td>...</td>\n",
              "      <td>Freq_52</td>\n",
              "      <td>Freq_53</td>\n",
              "      <td>Freq_54</td>\n",
              "      <td>Freq_55</td>\n",
              "      <td>Freq_56</td>\n",
              "      <td>Freq_57</td>\n",
              "      <td>Freq_58</td>\n",
              "      <td>Freq_59</td>\n",
              "      <td>Freq_60</td>\n",
              "      <td>Label</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.018</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.014</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.228</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.018</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 61 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  Feature_0 Feature_1 Feature_2 Feature_3 Feature_4 Feature_5 Feature_6  \\\n",
              "0    Freq_1    Freq_2    Freq_3    Freq_4    Freq_5    Freq_6    Freq_7   \n",
              "1      0.02    0.0371    0.0428    0.0207    0.0954    0.0986    0.1539   \n",
              "2    0.0453    0.0523    0.0843    0.0689    0.1183    0.2583    0.2156   \n",
              "3    0.0262    0.0582    0.1099    0.1083    0.0974     0.228    0.2431   \n",
              "4      0.01    0.0171    0.0623    0.0205    0.0205    0.0368    0.1098   \n",
              "\n",
              "  Feature_7 Feature_8 Feature_9  ... Feature_51 Feature_52 Feature_53  \\\n",
              "0    Freq_8    Freq_9   Freq_10  ...    Freq_52    Freq_53    Freq_54   \n",
              "1    0.1601    0.3109    0.2111  ...     0.0027     0.0065     0.0159   \n",
              "2    0.3481    0.3337    0.2872  ...     0.0084     0.0089     0.0048   \n",
              "3    0.3771    0.5598    0.6194  ...     0.0232     0.0166     0.0095   \n",
              "4    0.1276    0.0598    0.1264  ...     0.0121     0.0036      0.015   \n",
              "\n",
              "  Feature_54 Feature_55 Feature_56 Feature_57 Feature_58 Feature_59  Label  \n",
              "0    Freq_55    Freq_56    Freq_57    Freq_58    Freq_59    Freq_60  Label  \n",
              "1     0.0072     0.0167      0.018     0.0084      0.009     0.0032      R  \n",
              "2     0.0094     0.0191      0.014     0.0049     0.0052     0.0044      R  \n",
              "3      0.018     0.0244     0.0316     0.0164     0.0095     0.0078      R  \n",
              "4     0.0085     0.0073      0.005     0.0044      0.004     0.0117      R  \n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Import necessary libraries\n",
        "\n",
        "# Load the UCI Sonar dataset\n",
        "# The dataset can be downloaded from: https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\n",
        "# Assuming the file is named 'sonar.all-data.csv' and is in the current directory\n",
        "\n",
        "df = pd.read_csv('sonar.all-data.csv', header=None)\n",
        "# Assign column names: 60 features + 1 label\n",
        "df.columns = [f'Feature_{i}' for i in range(60)] + ['Label']\n",
        "\n",
        "# Display the first few rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total missing (NaN) values: 0\n"
          ]
        }
      ],
      "source": [
        "total_nans = df.isna().sum().sum()\n",
        "# Check for missing values\n",
        "print(\"Total missing (NaN) values:\", total_nans)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "label_counts = df.iloc[:, -1].value_counts()  # e.g. {'M': 111, 'R': 97}\n",
        "label_counts.plot(kind=\"bar\", color=[\"salmon\",\"skyblue\"])\n",
        "plt.title(\"Class Balance: R vs M\")\n",
        "plt.xlabel(\"Class (R=0, M=1)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imbalance ratio =  1.1443298969072164\n"
          ]
        }
      ],
      "source": [
        "#compute imbalance ratio\n",
        "count_R = label_counts[\"R\"]\n",
        "count_M = label_counts[\"M\"]\n",
        "larger = max(count_R, count_M)  # 111\n",
        "smaller = min(count_R, count_M) # 97\n",
        "imbalance_ratio = larger / smaller  # ≈ 1.144\n",
        "print(\"Imbalance ratio = \", imbalance_ratio)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With a ratio ≈ 1.14, the classes are almost evenly split (111 M vs 97 R), so we treat it as essentially balanced. No heavy resampling is required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (166, 60)\n",
            "X_test shape: (42, 60)\n"
          ]
        }
      ],
      "source": [
        "#PART 2 – Modelling\n",
        "#Train/Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Skip the first row, which contains feature names as data\n",
        "X = df.iloc[1:, :-1].astype(float).values\n",
        "y = df.iloc[1:, -1].astype(\"category\").cat.codes  # “R”→0, “M”→1\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, stratify=y, random_state=42\n",
        ")\n",
        "# Display the shapes of the train and test sets\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Five-Fold CV\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results for k=3:\n",
            "Train Acc: 0.9518\n",
            "Val Acc: 0.8494\n",
            "Gap: 0.1024\n",
            "Test Acc: 0.7143\n",
            "Precision: 0.7222\n",
            "Recall: 0.6500\n",
            "F1 Score: 0.6842\n",
            "Confusion Matrix:\n",
            " [[17  5]\n",
            " [ 7 13]]\n",
            "\n",
            "\n",
            "Results for k=5:\n",
            "Train Acc: 0.8961\n",
            "Val Acc: 0.8073\n",
            "Gap: 0.0888\n",
            "Test Acc: 0.7381\n",
            "Precision: 0.8000\n",
            "Recall: 0.6000\n",
            "F1 Score: 0.6857\n",
            "Confusion Matrix:\n",
            " [[19  3]\n",
            " [ 8 12]]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Evaluate Two Models: k = 3 and k = 5\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "def compute_knn_metrics(k, X_train, y_train, X_test, y_test):\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    train_accs = []\n",
        "    val_accs   = []\n",
        "\n",
        "    # Convert y_train to numpy array for positional indexing\n",
        "    y_train_np = np.array(y_train)\n",
        "\n",
        "    # 5‐fold CV on the TRAINING split\n",
        "    for train_idx, val_idx in skf.split(X_train, y_train_np):\n",
        "        X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
        "        y_tr, y_val = y_train_np[train_idx], y_train_np[val_idx]\n",
        "\n",
        "        # Scale fold‐train, fold‐val\n",
        "        scaler_fold = StandardScaler()\n",
        "        X_tr_scaled  = scaler_fold.fit_transform(X_tr)\n",
        "        X_val_scaled = scaler_fold.transform(X_val)\n",
        "\n",
        "        # Fit KNN on fold‐train\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        knn.fit(X_tr_scaled, y_tr)\n",
        "\n",
        "        # Training accuracy (on fold‐train)\n",
        "        y_tr_pred  = knn.predict(X_tr_scaled)\n",
        "        train_accs.append(accuracy_score(y_tr, y_tr_pred))\n",
        "\n",
        "        # Validation accuracy (on fold‐val)\n",
        "        y_val_pred = knn.predict(X_val_scaled)\n",
        "        val_accs.append(accuracy_score(y_val, y_val_pred))\n",
        "\n",
        "    mean_train_acc = np.mean(train_accs)\n",
        "    mean_val_acc   = np.mean(val_accs)\n",
        "    gap           = mean_train_acc - mean_val_acc\n",
        "\n",
        "    # Now evaluate on the held‐out TEST SET\n",
        "    # 1) Fit scaler on all of X_train, then transform both X_train & X_test\n",
        "    full_scaler = StandardScaler()\n",
        "    X_tr_all_scaled = full_scaler.fit_transform(X_train)\n",
        "    X_te_scaled     = full_scaler.transform(X_test)\n",
        "\n",
        "    # 2) Fit KNN(k) on full (scaled) X_train, predict on X_test\n",
        "    knn_final = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn_final.fit(X_tr_all_scaled, y_train_np)\n",
        "    y_test_pred = knn_final.predict(X_te_scaled)\n",
        "\n",
        "    # Convert y_test to numpy array for metrics\n",
        "    y_test_np = np.array(y_test)\n",
        "\n",
        "    test_acc = accuracy_score(y_test_np, y_test_pred)\n",
        "    prec     = precision_score(y_test_np, y_test_pred, pos_label=1)  # “M”=1\n",
        "    rec      = recall_score(y_test_np, y_test_pred, pos_label=1)\n",
        "    f1       = f1_score(y_test_np, y_test_pred, pos_label=1)\n",
        "    cm       = confusion_matrix(y_test_np, y_test_pred)\n",
        "\n",
        "    return {\n",
        "        'k':           k,\n",
        "        'Train Acc':  mean_train_acc,\n",
        "        'Val Acc':    mean_val_acc,\n",
        "        'Gap':        gap,\n",
        "        'Test Acc':   test_acc,\n",
        "        'Precision':  prec,\n",
        "        'Recall':     rec,\n",
        "        'F1':         f1,\n",
        "        'Conf Matrix': cm\n",
        "    }\n",
        "\n",
        "# Run for k=3 and k=5\n",
        "metrics_k3 = compute_knn_metrics(3, X_train, y_train, X_test, y_test)\n",
        "metrics_k5 = compute_knn_metrics(5, X_train, y_train, X_test, y_test)\n",
        "\n",
        "#Display the results\n",
        "def display_metrics(metrics):\n",
        "    print(f\"Results for k={metrics['k']}:\")\n",
        "    print(f\"Train Acc: {metrics['Train Acc']:.4f}\")\n",
        "    print(f\"Val Acc: {metrics['Val Acc']:.4f}\")\n",
        "    print(f\"Gap: {metrics['Gap']:.4f}\")\n",
        "    print(f\"Test Acc: {metrics['Test Acc']:.4f}\")\n",
        "    print(f\"Precision: {metrics['Precision']:.4f}\")\n",
        "    print(f\"Recall: {metrics['Recall']:.4f}\")\n",
        "    print(f\"F1 Score: {metrics['F1']:.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", metrics['Conf Matrix'])\n",
        "    print(\"\\n\")\n",
        "    \n",
        "display_metrics(metrics_k3)\n",
        "display_metrics(metrics_k5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q1: State the best model whichever model you would deploy if the main goal is to minimise missed mines (maximise recall).\n",
        "\n",
        "I would end up deploying k=3 because it recieved a Recall = 0.6500, where k=5 catches a Recall = 0.6000. k=5 did have a slightly higher Test Accuracy  (0.7381 vs. 0.7143), k=3 catches a larger fraction of actual mines (13/20 vs. 12/20). In mine-hunting a false negative would be far more dangerous than a false positive. So we pick the model with higher recall for class \"M\" even if overall accuracy is a little lower.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q2: Class imbalance – How severe is it, and which metric (precision vs recall) carries more significance in a sonar mine‑hunting scenario?\n",
        "\n",
        "The Sonar dataset contains 111 “M” labels and 97 “R” labels, yielding an imbalance ratio of about 1.14, which is so close to 1 that we consider the data nearly balanced,no heavy resampling techniques like SMOTE or undersampling are needed. In a mine-hunting context, however, the most critical metric is recall for the positive class (“M”), because missing a real mine (a false negative) could have catastrophic consequences. While precision (avoiding false alarms) is also important, a false positive, mistaking a rock for a mine—is merely an inconvenience, whereas a false negative risks actual detonation. Therefore, it makes sense to prioritize recall above all else, ensuring that as few mines as possible slip through undetected.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q3: k = 3 vs k = 5 – Compare validation vs. test results. Which k generalizes better?\n",
        "\n",
        "Validation (5-fold CV on training set):\n",
        "\n",
        "k=3 → Val Acc = 0.8494\n",
        "\n",
        "k=5 → Val Acc = 0.8073\n",
        "\n",
        "Verdict: k=3 looked stronger in‐fold (higher mean validation accuracy).\n",
        "\n",
        "Hold-out Test Set:\n",
        "\n",
        "k=3 → Test Acc = 0.7143, Recall = 0.6500\n",
        "\n",
        "k=5 → Test Acc = 0.7381, Recall = 0.6000\n",
        "\n",
        "Verdict (accuracy‐only): k=5 generalizes better in terms of raw Test Accuracy (0.7381 vs. 0.7143).\n",
        "\n",
        "Verdict (recall‐focused): k=3 generalizes better in terms of catching mines (0.6500 vs. 0.6000).\n",
        "\n",
        "Which k generalizes best depends on your metric: k=5 gives slightly higher overall test accuracy, but k=3 catches more mines (higher recall). Because missing a mine is far more critical, we choose k = 3.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q4:   Error profile – Using the confusion matrices, state whether false positives or false negatives dominate and discuss practical impact.\n",
        "\n",
        "k = 3 (Test Confusion Matrix)\n",
        "\n",
        "[[17  5]\n",
        "\n",
        " [ 7 13]]\n",
        "\n",
        "False Positives (FP) = 5 (rocks predicted as “M”).\n",
        "\n",
        "False Negatives (FN) = 7 (mines predicted as “R”).\n",
        "\n",
        "Here, FN (7) is slightly higher than FP (5). That means we miss 7 real mines while flagging 5 rocks incorrectly.\n",
        "\n",
        "k = 5 (Test Confusion Matrix)\n",
        "\n",
        "[[19  3]\n",
        "\n",
        " [ 8 12]]\n",
        "\n",
        "False Positives = 3 (fewer rocks misclassified).\n",
        "\n",
        "False Negatives = 8 (more mines missed).\n",
        "\n",
        "\n",
        "For both k=3 and k=5, the number of false negatives (mines missed) exceeds or nearly equals the number of false positives (rocks misclassified), meaning more real mines slip through than harmless rocks get flagged. Missing a mine (false negative) carries a far greater risk—potential detonation, while a false alarm is only an operational inconvenience. Therefore, reducing false negatives (maximizing recall) is the top priority, which is why k = 3 is preferred despite its slightly higher false-positive rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        0       1       2       3       4       5       6       7       8  \\\n",
            "0  Freq_1  Freq_2  Freq_3  Freq_4  Freq_5  Freq_6  Freq_7  Freq_8  Freq_9   \n",
            "1    0.02  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
            "2  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
            "3  0.0262  0.0582  0.1099  0.1083  0.0974   0.228  0.2431  0.3771  0.5598   \n",
            "4    0.01  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
            "\n",
            "         9  ...       51       52       53       54       55       56  \\\n",
            "0  Freq_10  ...  Freq_52  Freq_53  Freq_54  Freq_55  Freq_56  Freq_57   \n",
            "1   0.2111  ...   0.0027   0.0065   0.0159   0.0072   0.0167    0.018   \n",
            "2   0.2872  ...   0.0084   0.0089   0.0048   0.0094   0.0191    0.014   \n",
            "3   0.6194  ...   0.0232   0.0166   0.0095    0.018   0.0244   0.0316   \n",
            "4   0.1264  ...   0.0121   0.0036    0.015   0.0085   0.0073    0.005   \n",
            "\n",
            "        57       58       59  Label  \n",
            "0  Freq_58  Freq_59  Freq_60  Label  \n",
            "1   0.0084    0.009   0.0032      R  \n",
            "2   0.0049   0.0052   0.0044      R  \n",
            "3   0.0164   0.0095   0.0078      R  \n",
            "4   0.0044    0.004   0.0117      R  \n",
            "\n",
            "[5 rows x 61 columns]\n",
            "=== SVC (RBF) Results ===\n",
            "Mean Train Acc (5-fold CV): 0.9910\n",
            "Mean Val Acc   (5-fold CV): 0.8314\n",
            "Gap (Train − Val)       : 0.1596\n",
            "Test  Accuracy           : 0.8571\n",
            "Test  Precision (M=1)    : 0.9375\n",
            "Test  Recall (M=1)       : 0.7500\n",
            "Test  F1 Score (M=1)     : 0.8333\n",
            "Test  Confusion Matrix   :\n",
            "[[21  1]\n",
            " [ 5 15]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "# 1. Load the Sonar CSV (assumes sonar.all-data.csv is in the working directory)\n",
        "df = pd.read_csv(\"sonar.all-data.csv\", header=None)\n",
        "df.columns = list(range(df.shape[1] - 1)) + [\"Label\"]\n",
        "\n",
        "#display the first few rows\n",
        "print(df.head())\n",
        "\n",
        "# 2. Prepare X, y (skip the first row, which contains feature names as data)\n",
        "X = df.iloc[1:, :-1].astype(float).values\n",
        "y = df.iloc[1:, -1].astype(\"category\").cat.codes  # “R”→0, “M”→1\n",
        "\n",
        "# 3. Perform an 80/20 stratified split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, stratify=y, test_size=0.20, random_state=42\n",
        ")\n",
        "\n",
        "# 4. Helper function: 5-fold CV on X_train, y_train, returning train/val accuracies\n",
        "def cv_train_val_scores(clf_class, clf_params, X_tr, y_tr, n_splits=5):\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "    # Convert y_tr to numpy array for positional indexing\n",
        "    y_tr_np = np.array(y_tr)\n",
        "    for train_idx, val_idx in skf.split(X_tr, y_tr_np):\n",
        "        X_tr_fold, X_val_fold = X_tr[train_idx], X_tr[val_idx]\n",
        "        y_tr_fold, y_val_fold = y_tr_np[train_idx], y_tr_np[val_idx]\n",
        "\n",
        "        # Scale **only** the fold's training portion, then apply to fold's validation portion\n",
        "        scaler_fold = StandardScaler()\n",
        "        X_tr_scaled = scaler_fold.fit_transform(X_tr_fold)\n",
        "        X_val_scaled = scaler_fold.transform(X_val_fold)\n",
        "\n",
        "        clf = clf_class(**clf_params)\n",
        "        clf.fit(X_tr_scaled, y_tr_fold)\n",
        "\n",
        "        # Record training accuracy on that fold\n",
        "        y_tr_pred = clf.predict(X_tr_scaled)\n",
        "        train_accs.append(accuracy_score(y_tr_fold, y_tr_pred))\n",
        "\n",
        "        # Record validation accuracy on that fold\n",
        "        y_val_pred = clf.predict(X_val_scaled)\n",
        "        val_accs.append(accuracy_score(y_val_fold, y_val_pred))\n",
        "\n",
        "    return np.array(train_accs), np.array(val_accs)\n",
        "\n",
        "# 5. Run CV for SVC(RBF) on the training split\n",
        "train_accs_svc, val_accs_svc = cv_train_val_scores(SVC, {}, X_train, y_train)\n",
        "mean_train_svc = train_accs_svc.mean()\n",
        "mean_val_svc = val_accs_svc.mean()\n",
        "gap_svc = mean_train_svc - mean_val_svc\n",
        "\n",
        "# 6. Now evaluate SVC on the hold-out test set\n",
        "#    (a) Fit StandardScaler on **all** X_train and transform both X_train & X_test\n",
        "scaler_full = StandardScaler()\n",
        "X_train_scaled = scaler_full.fit_transform(X_train)\n",
        "X_test_scaled = scaler_full.transform(X_test)\n",
        "\n",
        "#    (b) Fit SVC on X_train_scaled, predict on X_test_scaled\n",
        "svc = SVC()  # default RBF kernel\n",
        "svc.fit(X_train_scaled, y_train)\n",
        "y_test_pred_svc = svc.predict(X_test_scaled)\n",
        "\n",
        "#    (c) Compute test metrics\n",
        "test_acc_svc = accuracy_score(y_test, y_test_pred_svc)\n",
        "prec_svc = precision_score(y_test, y_test_pred_svc, pos_label=1)\n",
        "rec_svc = recall_score(y_test, y_test_pred_svc, pos_label=1)\n",
        "f1_svc = f1_score(y_test, y_test_pred_svc, pos_label=1)\n",
        "cm_svc = confusion_matrix(y_test, y_test_pred_svc)\n",
        "\n",
        "# 7. Print out SVC results\n",
        "print(\"=== SVC (RBF) Results ===\")\n",
        "print(f\"Mean Train Acc (5-fold CV): {mean_train_svc:.4f}\")\n",
        "print(f\"Mean Val Acc   (5-fold CV): {mean_val_svc:.4f}\")\n",
        "print(f\"Gap (Train − Val)       : {gap_svc:.4f}\")\n",
        "print(f\"Test  Accuracy           : {test_acc_svc:.4f}\")\n",
        "print(f\"Test  Precision (M=1)    : {prec_svc:.4f}\")\n",
        "print(f\"Test  Recall (M=1)       : {rec_svc:.4f}\")\n",
        "print(f\"Test  F1 Score (M=1)     : {f1_svc:.4f}\")\n",
        "print(\"Test  Confusion Matrix   :\")\n",
        "print(cm_svc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "def plot_conf_matrix(cm, title):\n",
        "    plt.figure(figsize=(4,3))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "plot_conf_matrix(metrics_k3['Conf Matrix'], \"KNN (k=3) Confusion Matrix\")\n",
        "plot_conf_matrix(metrics_k5['Conf Matrix'], \"KNN (k=5) Confusion Matrix\")\n",
        "plot_conf_matrix(cm_svc, \"SVC (RBF) Confusion Matrix\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
